apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: alloy-logs
data:
  config.alloy: |
    discovery.kubernetes "pods" {
      role = "pod"
     
     // https://grafana.com/docs/alloy/latest/collect/prometheus-metrics/
     // this demonstrates configuring Alloy to collect data (metrics or logs) from running production Kubernetes Pods in the default Namespace.
    //  namespaces {
    //    own_namespace = false

    //    names = ["default"]
    //  }

    //  selectors {
    //    role  = "pod"
    //    label = "environment in (production)"
    //  }
    }

    discovery.relabel "pod_logs" {
      targets = discovery.kubernetes.pods.targets

      rule {
        source_labels = ["__meta_kubernetes_namespace"]
        target_label  = "namespace"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_name"]
        target_label  = "pod"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_container_name"]
        target_label  = "container"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
        action        = "replace"
        target_label  = "app"
      }

      rule {
        source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
        separator     = "/"
        target_label  = "job"
      }

      rule {
        source_labels = ["__meta_kubernetes_node_name"]
        target_label  = "node"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
        separator     = "/"
        action        = "replace"
        replacement   = "/var/log/pods/*$1/*.log"
        target_label  = "__path__"
      }

      rule {
        action        = "replace"
        source_labels = ["__meta_kubernetes_pod_container_id"]
        regex         = "^(\\\\w+):\\/\\/.+$"
        replacement   = "$1"
        target_label  = "tmp_container_runtime"
      }
    }

    // configuring Alloy to collect its own telemetry and forward it to the mimir backend.
    prometheus.exporter.self "default" {}

    prometheus.scrape "metamonitoring" {
      targets    = prometheus.exporter.self.default.targets
      forward_to = [prometheus.remote_write.mimir.receiver]
    }

    logging {
      level    = "warn"
      format   = "json"
      write_to = [loki.write.loki.receiver]
    }

    // tracing {
    //  sampling_fraction = 0.1
    //  write_to          = [otelcol.exporter.otlp.tempo.input]
    // }


    // System or Node logs
    // local.file_match discovers files on the local filesystem using glob patterns and the doublestar library. It returns an array of file paths.
    local.file_match "node_logs" {
      path_targets = [{
          // Monitor syslog to scrape node-logs
          __path__  = "/var/log/syslog",
          job       = "node/syslog",
          node_name = sys.env("HOSTNAME"),
          cluster   = "MillenniumFalcon",
      }]
    }

    // loki.source.file reads log entries from files and forwards them to other loki.* components.
    // You can specify multiple loki.source.file components by giving them different labels.
    loki.source.file "node_logs" {
      targets    = local.file_match.node_logs.targets
      forward_to = [loki.write.loki.receiver]
    }

    // Pods logs

    local.file_match "pod_logs" {
      path_targets = discovery.relabel.pod_logs.output
    }

    loki.source.file "pod_logs" {
      targets    = local.file_match.pod_logs.targets
      forward_to = [loki.process.pod_logs.receiver]
    }

    // Kubernetes Cluster Events

    loki.source.kubernetes_events "cluster_events" {
      job_name   = "integrations/kubernetes/eventhandler"
      log_format = "json"
      forward_to = [loki.process.cluster_events.receiver]
    }

    loki.process "pod_logs" {
      stage.static_labels {
        values = {
          cluster = "MillenniumFalcon",
        }
      }

      stage.match {
        selector = "{tmp_container_runtime=\"containerd\"}"
        stage.cri {}
        stage.labels {
          values = {
            flags  = "",
            stream = "",
          }
        }
      }

      stage.match {
        selector = "{tmp_container_runtime=\"docker\"}"
        stage.docker {}
        stage.labels {
          values = {
            stream = "",
          }
        }
      }

      stage.label_drop {
        values = ["tmp_container_runtime"]
      }

      stage.match {
        selector = "{namespace=~\"(monitoring|default|loki|mimir)\"}"
        stage.regex {
          expression = "(?P<method>GET|PUT|DELETE|POST)"
        }
        stage.regex {
          expression = "(?P<status_code_with_http_version>HTTP.{6}\\d{3})"
        }
        stage.regex {
          expression = "(?P<status_code>\\d{3})"
          source     = "status_code_with_http_version"
        }
        stage.labels {
          values = {
            method      = "",
            status_code = "",
          }
        }
      }

      stage.json {
        expressions = {
          level   = "level",
          app     = "app",
          env     = "env",
          message = "message",
        }
      }

      stage.regex {
        // This regex looks for 'trace_id' and 'span_id' keys followed by various characters,
        // then captures the hexadecimal ID. It's more tolerant of surrounding text.
        // It uses a non-greedy match (.*?) to capture the content between the key and the ID.
        
        expression = "(?:trace_id|TraceID|traceID)[^a-zA-Z0-9]*(?P<trace_id>[0-9a-fA-F]{32})|(?:span_id|SpanID|spanID)[^a-zA-Z0-9]*(?P<span_id>[0-9a-fA-F]{16})"
        
        // Explanation of the regex:
        // (?:trace_id|TraceID|traceID)   - Matches 'trace_id', 'TraceID', or 'traceID' (non-capturing group)
        // [^a-zA-Z0-9]* - Matches any non-alphanumeric character zero or more times (to handle ':', '=', spaces, quotes, etc.)
        // (?P<trace_id>[0-9a-fA-F]{32})   - Captures 32 hexadecimal characters into 'trace_id' named group
        // |                               - OR
        // (?:span_id|SpanID|spanID)     - Matches 'span_id', 'SpanID', or 'spanID'
        // [^a-zA-Z0-9]* - Same as above
        // (?P<span_id>[0-9a-fA-F]{16})    - Captures 16 hexadecimal characters into 'span_id' named group
        // Note: This regex assumes the standard lengths for Trace ID (32 hex chars) and Span ID (16 hex chars).
        // If your IDs can be different lengths, adjust {32} and {16} accordingly or use a broader match like +
      }

      stage.labels {
        values = {
          trace_id = "",    // Promote captured group to a label
          span_id  = "",    // Promote captured group to a label
        }
      }

      forward_to = [loki.write.loki.receiver]
    }

    loki.process "cluster_events" {
      stage.replace {
        expression = "(\"type\":\"Normal\")"
        replace = "\"type\":\"Normal\",\"level\":\"info\""
      }

      stage.replace {
        expression = "(\"type\":\"Warning\")"
        replace = "\"type\":\"Warning\",\"level\":\"warning\""
      }

      stage.json {
        expressions = {
          k8s_resource_kind = "kind",
          k8s_resource_name = "name",
          k8s_event_reason  = "reason",
          k8s_event_message = "message",
          k8s_event_type    = "type",
        }
      }

      stage.labels {
        values = {
          k8s_namespace_name = "namespace",
          k8s_resource_kind  = "k8s_resource_kind",
          k8s_event_reason   = "k8s_event_reason",
          k8s_event_type     = "k8s_event_type",
          k8s_resource_name  = "k8s_resource_name",
        }
      }

      stage.structured_metadata {
        values = {
          k8s_resource_name = "k8s_resource_name",
          k8s_event_message = "k8s_event_message",
        }
      }

      stage.label_keep {
        values = ["cluster", "organization", "region", "job", "k8s_namespace_name", "k8s_resource_kind", "k8s_event_reason", "k8s_event_type"]
      }

      forward_to = [loki.write.loki.receiver]
    }


    loki.write "loki" {
      endpoint {
        url = "http://loki-gateway.loki.svc.cluster.local/loki/api/v1/push"
        headers = {
          "Authorization" = "Basic bG9raS1jYW5hcnk6bG9raS1jYW5hcnk=",
          "X-Scope-OrgID" = "tenant1",
        }
      }
      external_labels = {
          "environment"      = "production",
          "region"   = "ap-southeast-1",
          "cluster"  = "MillenniumFalcon",
          }
    }

    otelcol.receiver.otlp "default" {
      grpc {
        endpoint = "0.0.0.0:4317"
      }
      http {}

      output {
        traces = [
          otelcol.processor.k8sattributes.default.input,
          otelcol.connector.spanlogs.default.input,
          otelcol.connector.spanmetrics.default.input,
          otelcol.connector.servicegraph.default.input,
        ]
      }
    }

    otelcol.processor.k8sattributes "default" {
      extract {
        metadata = [
          "k8s.namespace.name",
          "k8s.node.name",
          "k8s.pod.name",
          "k8s.container.name",
          "k8s.deployment.name",
          "k8s.statefulset.name",
          "k8s.daemonset.name",
          "container.image.tag",
        ]
      }

      output {
        traces = [otelcol.processor.batch.default.input]
      }
    }

    // https://grafana.com/docs/tempo/latest/configuration/grafana-alloy/span-metrics/#generate-metrics-from-spans
    otelcol.connector.spanmetrics "default" {
      dimension {
        name    = "http.method"
        default = "GET"
      }

      dimension {
        name = "http.target"
      }

      aggregation_temporality = "DELTA"

      histogram {
        explicit {
          buckets = ["50ms", "100ms", "250ms", "1s", "5s", "10s"]
        }
      }

      metrics_flush_interval = "15s"
      namespace              = "traces.spanmetrics"
      resource_metrics_key_attributes = ["service.name", "telemetry.sdk.language", "telemetry.sdk.name"]

      output {
        metrics = [otelcol.exporter.prometheus.default.input]
      }
    }

    otelcol.connector.servicegraph "default" {
      dimensions = ["http.method", "http.target", "service.name"]
      database_name_attributes = ["db.name"]
      latency_histogram_buckets = ["2ms", "4ms", "6ms", "8ms", "10ms", "50ms", "100ms", "200ms", "400ms", "800ms", "1s", "1400ms", "2s", "5s", "10s", "15s"]
      metrics_flush_interval = "15s"

      output {
        metrics = [otelcol.exporter.prometheus.default.input]
      }
    }

    otelcol.processor.batch "default" {
      timeout          = "500ms"
      send_batch_size  = 10000
      output {
        traces  = [otelcol.exporter.otlp.tempo.input]
        metrics = [otelcol.exporter.prometheus.default.input]
      }
    }

    otelcol.exporter.prometheus "default" {
      forward_to = [prometheus.remote_write.mimir.receiver]
    }

    prometheus.remote_write "mimir" {
      endpoint {
        url = "http://mimir-nginx.mimir.svc.cluster.local/api/v1/push"
        headers = {
          "Authorization" = "Basic bWltaXItbmdpbng6bWltaXItbmdpbng=",
        }
      }
      external_labels = {
          "env"      = "production",
          "region"   = "ap-southeast-1",
          "cluster"  = "MillenniumFalcon",
          }
    }

    otelcol.connector.spanlogs "default" {
      roots           = true
      span_attributes = ["http.method", "http.target"]
      labels = ["trace_id", "span_id", "service.name"]

      output {
        logs = [otelcol.exporter.loki.spanlogs_exporter.input]
      }
    }

    otelcol.exporter.otlp "tempo" {
      client {
        endpoint = "tempo-distributor.tempo.svc.cluster.local:4317"
        tls {
          insecure = true
          insecure_skip_verify = true
        }
      }
    }

    otelcol.exporter.loki "spanlogs_exporter" {
      forward_to = [loki.write.loki.receiver]
    }

    livedebugging {
      enabled = false
    }



  # kubectl create namespace alloy-logs

  # kubectl apply -f alloy-logs-configMap.yml

  # helm repo add grafana https:grafana.github.io/helm-charts
  # helm repo update

  # helm upgrade --install grafana-alloy grafana/alloy -f alloy-override-values.yaml --namespace alloy-logs

  # kubectl get pods -n alloy-logs -l app.kubernetes.io/name=grafana-alloy
  # kubectl logs -n alloy-logs -l app.kubernetes.io/name=grafana-alloy --tail=100
